{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "# import tensorflow as tf\n",
    "mnist = keras.datasets.mnist\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Conv2D, Dense, MaxPool2D, Flatten, BatchNormalization, Input, Dropout, concatenate\n",
    "\n",
    "from keras.preprocessing.image import *\n",
    "learning_rate = 0.0002\n",
    "input_shape = (28,28,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96000, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = np.load(\"line_data/images.npy\")\n",
    "l = np.load(\"line_data/labels0.npy\")\n",
    "w = np.load(\"line_data/labels1.npy\")\n",
    "c = np.load(\"line_data/labels2.npy\")\n",
    "a = np.load(\"line_data/labels3.npy\")\n",
    "a.shape\n",
    "\n",
    "\n",
    "# (x_train, y_train_length, y_train_width, y_train_color, y_train_angle) = (np.load('x_train.npy'), np.load('y_train_length.npy'), np.load('y_train_width.npy'), np.load('y_train_color.npy'), np.load('y_train_angle.npy'))\n",
    "# (x_test, y_test_length, y_test_width, y_test_color, y_test_angle) = (np.load('x_test.npy'), np.load('y_test_length.npy'), np.load('y_test_width.npy'), np.load('y_test_color.npy'), np.load('y_test_angle.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_block(x, filters):\n",
    "#     last = x\n",
    "\n",
    "    net1 = Conv2D(filters = filters, kernel_size=(1,1), padding='Same', activation = 'relu')(x)\n",
    "\n",
    "    net2 = Conv2D(filters = filters, kernel_size=(1,1), padding='Same', activation = 'relu')(x)\n",
    "    net2 = Conv2D(filters = filters, kernel_size=(3,3), padding='Same', activation = 'relu')(net2)\n",
    "\n",
    "    net3 = Conv2D(filters = filters, kernel_size=(1,1), padding='Same', activation = 'relu')(x)\n",
    "    net3 = Conv2D(filters = filters, kernel_size=(3,3), padding='Same', activation = 'relu')(net3)\n",
    "    net3 = Conv2D(filters = filters, kernel_size=(3,3), padding='Same', activation = 'relu')(net3)\n",
    "\n",
    "    output = concatenate([net1, net2, net3], axis=3)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nadeemqwerty/.local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# def inception_block(x, filters):\n",
    "# #     last = x\n",
    "\n",
    "#     net1 = Conv2D(filters = filters, kernel_size=(1,1), padding='Same', activation = 'relu')(x)\n",
    "\n",
    "#     net2 = Conv2D(filters = filters, kernel_size=(1,1), padding='Same', activation = 'relu')(x)\n",
    "#     net2 = Conv2D(filters = filters, kernel_size=(3,3), padding='Same', activation = 'relu')(net2)\n",
    "\n",
    "#     net3 = Conv2D(filters = filters, kernel_size=(1,1), padding='Same', activation = 'relu')(x)\n",
    "#     net3 = Conv2D(filters = filters, kernel_size=(3,3), padding='Same', activation = 'relu')(net3)\n",
    "#     net3 = Conv2D(filters = filters, kernel_size=(3,3), padding='Same', activation = 'relu')(net3)\n",
    "\n",
    "#     output = concatenate([net1, net2, net3], axis=3)\n",
    "#     return output\n",
    "\n",
    "input_shape = (28,28,3)\n",
    "\n",
    "input_layer = Input(shape=input_shape)\n",
    "x = Conv2D(filters = 32, kernel_size=(5,5), padding='Same', activation = 'relu')(input_layer)\n",
    "x = Conv2D(filters = 32, kernel_size=(5,5), padding='Same', activation = 'relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPool2D(pool_size=(5, 5), strides=(2,2))(x)\n",
    "\n",
    "# last = x\n",
    "\n",
    "x = inception_block(x,32)\n",
    "x = MaxPool2D(pool_size=(5, 5), strides=(2,2),padding='Same')(x)\n",
    "\n",
    "# x = MaxPool2D(pool_size=(3, 3), strides=(2,2))(x)\n",
    "# x = inception_block(x,64)\n",
    "# x = MaxPool2D(pool_size=(3, 3), strides=(1,1),padding='Same')(x)\n",
    "\n",
    "x = inception_block(x,64)\n",
    "x = MaxPool2D(pool_size=(3, 3), strides=(1,1),padding='Same')(x)\n",
    "\n",
    "# x = concatenate([x, last], axis=3)\n",
    "# x = Conv2D(filters = 128, kernel_size=(3,3), padding='Same', activation = 'relu')(x)\n",
    "# x = Conv2D(filters = 128, kernel_size=(3,3), padding='Same', activation = 'relu')(x)\n",
    "# x = MaxPool2D(pool_size=(3, 3), strides=(1,1))(x)\n",
    "\n",
    "# x = Conv2D(filters = 128, kernel_size=(3,3), padding='Same', activation = 'relu')(x)\n",
    "# x = Conv2D(filters = 128, kernel_size=(3,3), padding='Same', activation = 'relu')(x)\n",
    "# x = MaxPool2D(pool_size=(3, 3), strides=(2,2),padding='Same')(x)\n",
    "\n",
    "# x = Conv2D(filters = 256, kernel_size=(3,3), padding='Same', activation = 'relu')(x)\n",
    "# x = Conv2D(filters = 256, kernel_size=(3,3), padding='Same', activation = 'relu')(x)\n",
    "# x = MaxPool2D(pool_size=(3, 3), strides=(1,1),padding='Same')(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "# x = Dense(2048, activation=tf.nn.relu)(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# x = Dense(128, activation=tf.nn.relu)(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(96, activation='softmax')(x)\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "model = Model(input_layer, x)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"weight/line_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers.pop()\n",
    "model.layers[-1].outbound_nodes = []\n",
    "\n",
    "model.layers.pop()\n",
    "model.layers[-1].outbound_nodes = []\n",
    "\n",
    "model.layers.pop()\n",
    "model.layers[-1].outbound_nodes = []\n",
    "\n",
    "# model.layers.pop()\n",
    "# model.layers[-1].outbound_nodes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.layers.pop()\n",
    "# model.layers.pop()\n",
    "\n",
    "# model = Model(model.input, model.layers[-4])\n",
    "inp = model.input\n",
    "opt = model.layers[-1].output\n",
    "# exc = Model(model.input, opt)\n",
    "# exc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()\n",
    "exc = Model(inp, opt)\n",
    "exc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = exc.predict(images)\n",
    "# pred_test = exc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_train = pred_train.reshape((28800,6912,1,1))\n",
    "pred_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = Sequential()\n",
    "length.add(Dense(1024, input_dim = 6912, activation='relu'))\n",
    "\n",
    "length.add(Dense(1, activation='sigmoid'))\n",
    "length.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "#               loss_weights = loss_weights,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "l_history = length.fit(pred_train, l, epochs=16, batch_size=32,validation_split=0.4, shuffle=True,verbose=1)\n",
    "model.save_weights(\"length_head.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length.evaluate(pred_test, y_test_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = Sequential()\n",
    "width.add(Dense(1, input_dim = 6912, activation='sigmoid'))\n",
    "width.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "#               loss_weights = loss_weights,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "w_history = width.fit(pred_train, w, epochs=3, batch_size=32,validation_split=0.01, shuffle=True,verbose=1)\n",
    "model.save_weights(\"width_head.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# width.evaluate(pred_test, y_test_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = Sequential()\n",
    "color.add(Dense(1, input_dim = 6912, activation='sigmoid'))\n",
    "color.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "#               loss_weights = loss_weights,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "c_history = color.fit(pred_train, c, epochs=3, batch_size=32,validation_split=0.01, shuffle=True,verbose=1)\n",
    "model.save_weights(\"color_head.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color.evaluate(pred_test, y_test_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = Sequential()\n",
    "angle.add(Dense(256, input_dim = 6912, activation='relu'))\n",
    "angle.add(Dropout(0.5))\n",
    "angle.add(Dense(12, activation='softmax'))\n",
    "angle.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "#               loss_weights = loss_weights,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "a_history = angle.fit(pred_train, a, epochs=12, batch_size=32,validation_split=0.4, shuffle=True,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
